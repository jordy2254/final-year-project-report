\section{Implementation/Development}
The following chapter will cover interesting problems that arose during development, including why they where interesting, how they happened, and how the problem was solved. In addition to this the chapter will also cover the key stages of development and the produced artefacts comparing to that of the user stories/requirements identified above

\subsection{Encountered issues}
\subsubsection{Room Polygon calculation}
As defined in the design, the rooms will be stored as overlapping rectangles and then later drawn to the screen. The process of calculating the walls and polygon for this was a lot more complicated than initially anticipated. Various google searches for this problem returned no results as such a custom algorithm was designed to achieve the goal. Below is the information on the basic overview of how this algorithm works.\\

There's several key steps for generating the polygon, the first of these steps is calculating the walls (excluding entrances) that exist for the given shape, this starts out as 2 separate lists of walls one for the room and one for all the indents. after this the room walls are adjusted to account for these, this is done by checking for a collision walls and editing the current points of the room wall. There are 3 different states that can occur when comparing the wall with the overlapping area, these are:
\begin{itemize}
	\item Indent starts at the same point as the wall (Original wall is removed)
	\item Indent starts after the start point of the wall (Original wall is adjusted to meet the start point)
	\item Indent ends before the end point of the wall (A new wall is added to cover the extra area)
	\item Indent ends at the same point as the wall (No change necessary)	
\end{itemize}
Below is a visualisation of how the algorithm works for each state and the final result.
\begin{center}
	\includegraphics{example-image-b}
\end{center}

Once this has been done depending if the actual walls or polygon is generated depends on what happens, if the actual walls are being done, and further cut-outs are then made on the whole set based on the same logic above and then that set is returned. If however the polygon is being generated some further processing is needed to ensure the start point of a wall matches an end point of another, this is done by looping the data and flipping the points based on a parity where an even parity (end points -> matching start point) is desired. Once this has been done the points can be followed around generation a list of 2d points that can be used to generate a 2d polygon.

Further work in the future would allow one of many triangulation methods to be used in order to generate a 2d polygon for OpenGL, further expansion could also turn this so that walls are added to the outside as a further polygon so that a 3d projection can be drawn, however both of these are out of scope for the project currently.


\subsubsection{Positioning System/location Calculation}
Location calculation turned out to be a task that couldn't be achieved, the project was ambitious wanting to implement a full indoor mapping system with indoor positioning. Early iterations of the project focussed primarily on the infrastructure of the mapping system as opposed to the location calculation in itself as such it wasn't realised until late into the project the issues that would occur.

The main reason for the failure of this area of the system was possibly because of hardware. The calculated distance measurement was perceived to be sporadic at best with a distance of 1m being calculated as 0cm-200cm. The distance value being calculated on each update would change considerably with large changes being more common (>50cm). Due to the rapid changes of the change and lack of a reliable measurement it was established that this wouldn't be applicable in the current state so several options where attempted to solve this. The first option was adding more sensor's to see if this would at least render something useable, doing this only highlighted the irregular measurement pattern and further proved this method wasn't reliable.
After this attempts at normalising the data by averaging or throwing out large changes where used both of these methods didn't work either on there own or combined. Doing this also highlighted that deciphering a good measurement from a bad one was difficult without already knowing where the user is which destroys the use of this system, even if this was possible an accurate enough measurement was only obtained in \textgreater2 second intervals but normally closer to 4.

On a positive note the research done did show Bluetooth being a viable option with a range of solutions being developed as a proof of concept such as \citetemp. For this reason it's believed the cause of these sporadic measurements stems from the hardware used which was a BBC microbit. This could be down to the limitations of the runtime being used, the Bluetooth driver, the antenna of the Bluetooth chip or other reasons. Sadly by the time these conclusions where reached it was too close to the projects deadline to be able to order different hardware such that these theory's can be confirmed thus the focus for the remaining portion of the project changed to polishing the rest of the indoor mapping system and android application.

\subsection{Interesting development}
\subsubsection{Rendering engine}
Mostly as learning exercise a custom pixel based rendering system was written for the rendering of the maps. The writing of this code allowed the learning and research of a range of algorithms for drawing shapes such as: lines, filled polygons, circles and more. All of this gave a great insight and experience into what happens on the back-end of drawing surfaces and canvas APIs within more complicated systems. The key point of the render engine is it contains a Screen class which just uses plain Java with it's data being stored in an integer array representing the pixels. This screen class features all the various functions developed for rendering the shapes listed above.\\

An unintended advantage for the development of this system was that is separated all the rendering logic from platform specific canvas APIs into it's own API where the only platform specific code is the pushing of this pixel data into a bitmap and finally onto a canvas supplied by android's canvas API. Having this means it's easier to port the code over to a new system as all of the rendering is now independent of android's SDK, below is a brief overview of the developed render engine a green box is platform independent and the 

\subsubsection{Dynamic path nodes \& path finding}
As part of development it was required that a custom point can be added into the path network, so that the path finding algorithm can perform an accurate calculation. A utility class was designed to take the path network and then dynamically link new nodes to that graph. This was achieved by taking the map data and then using a projection it would link to all other nodes, if the projection hits a wall before the path node then a link is not established otherwise a bi-directional link is created to that node. The utility class keeps track of all these dynamic nodes so that only the dynamic nodes can be amended leaving all original data intact. When existing the program of before serialisation of the map the utility is used to destroy all links and the created node. The main interaction of this system is done by the "waypoint" system which stores the user's desired points, the waypoint system returns a path node when called which is fed into the path finding algorithm of which the result is displayed to the user.


\subsection{Implementation Artefacts}
The below section is going to highlight the different results of the implementation, this will mostly consist of some screenshots of each section of the program. The aim of this is to demonstrate the basic overview of what was developed as part of the system.

\subsubsection{Web}
\subsubsection{Android}
\subsubsection{Rest API}


